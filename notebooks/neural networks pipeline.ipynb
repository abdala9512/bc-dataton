{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yellow-tiger",
   "metadata": {},
   "source": [
    "# NN Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler, RobustScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization,Dropout, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from scipy.special import boxcox1p, inv_boxcox1p\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "matplotlib.rc('xtick', labelsize=15)\n",
    "matplotlib.rc('ytick', labelsize=15)\n",
    "plt.rcParams['figure.figsize'] = [16.0, 10.0]\n",
    "\n",
    "def mean_absolute_percentage_error(y_pred, y_true):\n",
    "    y_true = np.where(y_true == 0, 0.0000000001, y_true)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-institution",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFramePreProcessor:\n",
    "    \n",
    "    def __init__(self, dataframe, test=False):\n",
    "        self.test = test\n",
    "        self.original_dataframe = dataframe.copy()\n",
    "        self.modeling_dataframe = None\n",
    "\n",
    "    \n",
    "    \n",
    "    def handleMissingData(self, dataframe):\n",
    "        dataframe['ingreso_final'] = dataframe['ingreso_final'].fillna(0)\n",
    "        dataframe['ind'] = dataframe['ind'].fillna(0)\n",
    "        dataframe['tipo_vivienda'] = dataframe['tipo_vivienda'].fillna(\"NO INFORMA\")\n",
    "        dataframe['categoria'] = dataframe['categoria'].fillna(\"6\")\n",
    "        dataframe['estado_civil'] =dataframe['estado_civil'].fillna(\"NI\")\n",
    "        #dataframe['departamento_residencia'] = dataframe['departamento_residencia'].fillna(\"SIN INFORMACION\")\n",
    "        #dataframe['ocupacion'] = dataframe['ocupacion'].fillna(\"Otro\")\n",
    "        dataframe['ind_mora_vigente']  = dataframe['ind_mora_vigente'].fillna(\"N\") \n",
    "        return dataframe\n",
    "    \n",
    "    \n",
    "    def columnFilter(self, dataframe):\n",
    "        to_drop = [\n",
    "            \"Unnamed: 0\",\n",
    "            \"id_cli\",\n",
    "            \"pol_centr_ext\",\n",
    "            \"ult_actual\",\n",
    "            \"cant_mora_30_tdc_ult_3m_sf\",\n",
    "            \"cant_mora_30_consum_ult_3m_sf\",\n",
    "            #\"ind\",\n",
    "            \"cat_ingreso\",\n",
    "            \"departamento_residencia\",\n",
    "            \"ocupacion\",\n",
    "            \"estado_civil\",\n",
    "            \"tipo_vivienda\",\n",
    "            \"nivel_academico\",\n",
    "            \"rep_calif_cred\",\n",
    "            \"tiene_ctas_activas\",\n",
    "            \"mora_max\"\n",
    "            \n",
    "        ]\n",
    "        \n",
    "            \n",
    "        dataframe = dataframe.drop(to_drop,axis=1, errors='ignore')\n",
    "        return dataframe\n",
    "    \n",
    "    \n",
    "    # Borrar filas deacuerdo a cierta logica de negocio\n",
    "    def rowFilter(self, dataframe):\n",
    "        cut = 0.999999\n",
    "        return  dataframe[\n",
    "                (dataframe['gasto_familiar'] >= 50000) &\n",
    "                (dataframe['gasto_familiar'] < np.quantile(dataframe['gasto_familiar'], cut)) &\n",
    "                (dataframe['ingreso_final'] < np.quantile(dataframe['ingreso_final'], cut)) &\n",
    "                (dataframe['cupo_total_tc'] < np.quantile(dataframe['cupo_total_tc'], cut)) & # Percentil 99%\n",
    "                (dataframe['cuota_tc_bancolombia'] < np.quantile(dataframe['cuota_tc_bancolombia'], cut)) & # percentil 99.99%\n",
    "                (dataframe['cuota_de_vivienda'] < np.quantile(dataframe['cuota_de_vivienda'], cut)) &# Percentil 99.99%\n",
    "                (dataframe['cuota_de_consumo'] < np.quantile(dataframe['cuota_de_consumo'], cut)) & # percentil 99%\n",
    "                (dataframe['cuota_rotativos'] < np.quantile(dataframe['cuota_rotativos'], cut))& # percentil 99.99%\n",
    "                (dataframe['cuota_tarjeta_de_credito'] < np.quantile(dataframe['cuota_tarjeta_de_credito'], cut)) & \n",
    "                (dataframe['cuota_de_sector_solidario'] < np.quantile(dataframe['cuota_de_sector_solidario'], cut)) &\n",
    "                (dataframe['cuota_sector_real_comercio'] < np.quantile(dataframe['cuota_sector_real_comercio'], cut)) &# Percentil 99.5%\n",
    "                (dataframe['cuota_libranza_sf'] < np.quantile(dataframe['cuota_libranza_sf'], cut)) & # Percentil 99\n",
    "                (dataframe['ingreso_segurida_social'] < np.quantile(dataframe['ingreso_segurida_social'], cut)) & # percentil 99.9\n",
    "                (dataframe['ingreso_nomina'] < np.quantile(dataframe['ingreso_nomina'], cut)) &\n",
    "                (dataframe['saldo_prom3_tdc_mdo'] < np.quantile(dataframe['saldo_prom3_tdc_mdo'], cut)) &\n",
    "                (dataframe['saldo_no_rot_mdo'] < np.quantile(dataframe['saldo_no_rot_mdo'], cut)) &\n",
    "                (dataframe['cuota_cred_hipot'] < np.quantile(dataframe['cuota_cred_hipot'], cut)) &\n",
    "                (dataframe['mediana_nom3'] < np.quantile(dataframe['mediana_nom3'], cut)) &\n",
    "                (dataframe['mediana_pen3'] < np.quantile(dataframe['mediana_pen3'], cut)) &\n",
    "                (dataframe['cuota_tc_mdo'] < np.quantile(dataframe['cuota_tc_mdo'], cut)) &\n",
    "                (dataframe['ingreso_nompen'] < np.quantile(dataframe['ingreso_nompen'], cut)) &\n",
    "                (dataframe['cant_oblig_tot_sf'] <= 15) &\n",
    "                (dataframe['ctas_activas'] < 5) &\n",
    "                (dataframe['nro_tot_cuentas'] < 5) &\n",
    "                (dataframe['ind_mora_vigente'] != 'NApl') &\n",
    "                (dataframe['ind'] < np.quantile(dataframe['ind'], cut))\n",
    "              #  ~(dataframe['departamento_residencia'].isin(['MADRID', 'ESTADO DE LA FLORIDA', 'VAUPES']))\n",
    "            ] \n",
    "    \n",
    "    def oneEncodeVariables(self):\n",
    "        pass\n",
    "    \n",
    "    def processVars(self, dataframe):\n",
    "        \n",
    "        # Transformacion demograficas\n",
    "        dataframe['genero'] = np.where(dataframe['genero'] == 'M', 0, 1)\n",
    "        #dataframe['edad'] = np.where(dataframe['edad'] < 18, 18,\n",
    "        #                            np.where(dataframe['edad'] > 80, 80, dataframe['edad']\n",
    "        #                            ))\n",
    "       # dataframe['educacion_grupo'] = np.where(\n",
    "       #     dataframe['nivel_academico'].isin(['PRIMARIO', 'UNIVERSITARIO', 'ESPECIALIZACION']),1,0\n",
    "       #)\n",
    "        #dataframe['ind_caida_gasto'] = np.where(dataframe['periodo'] == 202004,1,0)\n",
    "        #dataframe['ind_caida_cuota'] = np.where(dataframe['periodo'] == 202009,1,0)\n",
    "        #dataframe['tipo_vivienda'] =  np.where(dataframe['tipo_vivienda'].isin([\"\\\\N\", \"NO INFORMA\"]),\"OTRO\",\n",
    "        #                                       np.where(dataframe['tipo_vivienda'].isin(['FAMILIAR','ALQUILADA']), \"FAM_ALQ\",\n",
    "        #                                                dataframe['tipo_vivienda']\n",
    "        #                                               )\n",
    "        #                                     )\n",
    "        dataframe['categoria']=np.where(dataframe['categoria']=='\\\\N', \"6\",dataframe['categoria'])\n",
    "        dataframe['categoria']=dataframe['categoria'].astype(float).astype(int)\n",
    "        #dataframe['ocupacion']=np.where(dataframe['ocupacion'].isin(\n",
    "        #        [\"\\\\N\", \"Agricultor\", \"Ganadero\", 'Vacío', \"Ama de casa\", \"Sin Ocupacion Asignada\"]), \"Otro\",\n",
    "        #                               np.where(dataframe['ocupacion'] == \"Pensionado\", \"Jubilado\", dataframe['ocupacion']\n",
    "        #                                       ))\n",
    "        \n",
    "        #dataframe['departamento_residencia'] = \\\n",
    "        #    np.where(\n",
    "        #        dataframe['departamento_residencia'].isin(['\\\\N', 'NARIÑO', 'NARI#O', 'VAUPES','MADRID', 'ESTADO DE LA FLORIDA']),\n",
    "        #        \"SIN INFORMACION\", dataframe['departamento_residencia'] )\n",
    "        \n",
    "        #dataframe['es_ciudad_principal'] = np.where(\n",
    "        #    dataframe['departamento_residencia'].isin(['BOGOTA D.C.', 'ANTIOQUIA', 'VALLE', 'CUNDINAMARCA']), 1,0)  \n",
    "        #dataframe['estado_civil'] = np.where(dataframe['estado_civil'].isin(['NI', 'VIU', 'OTRO', 'NI', 'DIV']), \n",
    "        #                                     \"OTRO\", dataframe['estado_civil'])\n",
    "        \n",
    "        #dataframe['ind_mora_vigente'] = np.where(dataframe['ind_mora_vigente'] == \"S\", 1, 0)\n",
    "        dataframe['convenio_lib'] = np.where(dataframe['convenio_lib'] == 'S', 1, 0)\n",
    "        # Transformacion finacieras\n",
    "        dataframe['ingreso_calculado'] =  dataframe['ingreso_segurida_social']  +  \\\n",
    "                                          dataframe[['ingreso_nompen', 'ingreso_nomina']].max(axis=1)\n",
    "        dataframe['ingreso_corr'] = dataframe[['ingreso_final', 'ingreso_calculado']].max(axis=1)\n",
    "        \n",
    "        dataframe['cuota_cred_hipot'] = dataframe[['cuota_cred_hipot', 'cuota_de_vivienda']].max(axis=1)\n",
    "        dataframe['cuota_de_consumo'] =np.where(dataframe['cuota_de_consumo'] < 0, 0, dataframe['cuota_de_consumo'])\n",
    "        dataframe['cuota_cred_hipot'] =np.where(dataframe['cuota_cred_hipot'] < 0, 0, dataframe['cuota_cred_hipot']) \n",
    "        \n",
    "        dataframe['total_cuota'] = dataframe['cuota_cred_hipot'] + \\\n",
    "                                   dataframe['cuota_tarjeta_de_credito'] + \\\n",
    "                                   dataframe['cuota_de_consumo'] + \\\n",
    "                                   dataframe['cuota_rotativos'] + \\\n",
    "                                   dataframe['cuota_de_sector_solidario'] + \\\n",
    "                                   dataframe['cuota_libranza_sf'] + \\\n",
    "                                   dataframe['cuota_tarjeta_de_credito'] + \\\n",
    "                                   dataframe['cuota_tc_bancolombia']\n",
    "        \n",
    "        #dataframe['saldo_favor']  = np.where(dataframe['total_cuota']<0, dataframe['total_cuota']*-1, 0)\n",
    "        dataframe['total_cuota'] = np.where(dataframe['total_cuota']<0,0, dataframe['total_cuota'])\n",
    "\n",
    "        #dataframe['cat_edad'] = np.where(dataframe['edad'] < 30, \"M30\",\n",
    "        #                          np.where(dataframe['edad'] < 40, \"M30_40\",\n",
    "        #                                  np.where(dataframe['edad'] < 50, \"M40_50\", \"M60\")))\n",
    "                \n",
    "        pct_vars = [\n",
    "            'cuota_cred_hipot',\n",
    "            'cuota_tarjeta_de_credito',\n",
    "            'cuota_de_consumo',\n",
    "            'cuota_rotativos',\n",
    "            'cuota_sector_real_comercio',\n",
    "            'cuota_de_sector_solidario',\n",
    "            'cuota_tc_bancolombia',\n",
    "            'cuota_libranza_sf',\n",
    "            'cupo_total_tc',\n",
    "            'cupo_tc_mdo'\n",
    "        ]\n",
    "        \n",
    "        for var in pct_vars:\n",
    "            dataframe[f\"{var}_pct\"] = dataframe[var] / dataframe['ingreso_corr']  * 100\n",
    "            dataframe[f\"{var}_pct\"] = dataframe[f\"{var}_pct\"].replace(dict.fromkeys([np.nan, np.inf, -np.inf], 0))\n",
    "            #dataframe[f\"{var}_2\"]   = dataframe[var] ** 2\n",
    "    \n",
    "        dataframe['obl_total_pct'] = dataframe['cuota_cred_hipot_pct'] + \\\n",
    "                                     dataframe['cuota_tarjeta_de_credito_pct'] +\\\n",
    "                                     dataframe['cuota_de_consumo_pct'] + \\\n",
    "                                     dataframe['cuota_rotativos_pct'] + \\\n",
    "                                     dataframe['cuota_sector_real_comercio_pct'] + \\\n",
    "                                     dataframe['cuota_de_sector_solidario_pct'] + \\\n",
    "                                     dataframe['cuota_tc_bancolombia_pct'] + \\\n",
    "                                     dataframe['cuota_rotativos_pct'] \n",
    "        \n",
    "                                    \n",
    "\n",
    "        #dataframe['sobre_endeudado'] = np.where(dataframe['obl_total_pct'] > 100, 1, 0)\n",
    "        dataframe['total_cupo'] = dataframe['cupo_total_tc'] + dataframe['cupo_tc_mdo']\n",
    "        #dataframe['ingreso_cero'] = np.where(dataframe['ingreso_corr'] == 0, 1, 0)\n",
    "        \n",
    "        # Variables de interaccion\n",
    "        #dataframe['interact_ing_gen']  = dataframe['genero'] * dataframe['ingreso_corr']\n",
    "        #dataframe['interact_ing_ed']  = dataframe['edad'] * dataframe['ingreso_corr']\n",
    "        #dataframe['interact_cup_gen']  = dataframe['genero'] * dataframe['total_cupo']\n",
    "        #dataframe['interact_cup_ed']  = dataframe['edad'] * dataframe['total_cupo']\n",
    "        #dataframe['interact_obl_gen'] = dataframe['genero'] * dataframe['obl_total_pct']\n",
    "        #dataframe['interact_obl_ed']  = dataframe['edad'] * dataframe['obl_total_pct']    \n",
    "        #dataframe['interact_caida_ing'] = dataframe['ingreso_corr']*dataframe['ind_caida_gasto']\n",
    "        #dataframe['interact_mora_ing'] = dataframe['ingreso_corr']*dataframe['ind_mora_vigente']\n",
    "        #dataframe['interact_mora_cuota'] = dataframe['total_cuota']*dataframe['ind_mora_vigente']\n",
    "        #dataframe['interact_caida_cuota'] = dataframe['ind_caida_cuota'] * dataframe['total_cuota']\n",
    "        \n",
    "        #dataframe['ingreso_geo_alto']  = np.where(dataframe['ingreso_corr'] < 14.90, 1, 0) # ALgo mas tecnico\n",
    "\n",
    "    \n",
    "        #dataframe['pc25'] = np.where(dataframe['ingreso_corr'] <= np.quantile(dataframe['ingreso_corr'],0.25), 1, 0)\n",
    "        #dataframe['pc75'] = np.where(dataframe['ingreso_corr'] >= np.quantile(dataframe['ingreso_corr'],0.75), 1, 0)\n",
    "\n",
    "        # variables al cuadrado\n",
    "        \n",
    "        #dataframe['edad_2'] = dataframe['edad']**2\n",
    "        dataframe['total_cuota_2']  =dataframe['total_cuota']**2\n",
    "        #dataframe['total_cupo_2']  =dataframe['total_cupo']**2\n",
    "        #dataframe['obl_total_pct_2'] = dataframe['obl_total_pct']**2\n",
    "        #dataframe['ingreso_corr2'] = dataframe['ingreso_corr']**2 \n",
    "        \n",
    "        \n",
    "        # Raiz de las variables\n",
    "        \n",
    "        #dataframe['cupo_pct'] = dataframe['total_cupo']/dataframe['ingreso_corr']\n",
    "        #dataframe['cupo_disponible'] = dataframe['total_cupo'] - dataframe['cuota_tarjeta_de_credito'] - \\\n",
    "         #                              dataframe['cuota_tc_bancolombia']\n",
    "        #dataframe['liquidez'] = dataframe['cupo_disponible'] + dataframe['ingreso_corr']\n",
    "        #dataframe['liquidez_c'] = dataframe['total_cupo'] + dataframe['ingreso_corr']\n",
    "        #dataframe['cuota_pct_cupo'] = (dataframe['cuota_tarjeta_de_credito'] + dataframe['cuota_tc_bancolombia']) / dataframe['total_cupo']\n",
    "        #dataframe['ind_corregido'] = dataframe['ingreso_corr'] - dataframe['total_cuota'] - dataframe['ingreso_corr']*0.1\n",
    "        #dataframe['ratio_cupo'] = dataframe['cupo_tc_mdo']/dataframe['cupo_tc_mdo']\n",
    "        \n",
    "        dataframe.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        dataframe.fillna(0, inplace=True)\n",
    "        dataframe['periodo'] = dataframe['periodo'].astype(str)\n",
    "        #dataframe = dataframe.merge(indicators.drop(['inflacion'], axis=1), left_on='periodo', right_on='Fecha')\n",
    "        \n",
    "        if not self.test:\n",
    "            #dataframe['gasto_familiar'] = np.where(dataframe['gasto_familiar'] <= 0,\n",
    "            #                                       1,\n",
    "            #                                      dataframe['gasto_familiar'])\n",
    "            \n",
    "            dataframe['log_gasto_familiar'] = np.log1p(dataframe['gasto_familiar']) \n",
    "            #dataframe['log_gasto_familiar'] = np.sqrt(dataframe['gasto_familiar'])\n",
    "            numeric_feats = dataframe.drop(['gasto_familiar', 'log_gasto_familiar'], axis=1).dtypes[\n",
    "                    (dataframe.dtypes == \"float64\")].index\n",
    "        else:\n",
    "            numeric_feats = dataframe.dtypes[\n",
    "                    (dataframe.dtypes == \"float64\")].index\n",
    "            \n",
    "        skewed_feats = dataframe[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "        skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "        skewness = skewness[abs(skewness) > 0.75]       \n",
    "        skewed_features = skewness.index\n",
    "        lam = 0.1\n",
    "        PT_transformer = PowerTransformer()\n",
    "        for feat in skewed_features:\n",
    "             #dataframe[feat] = boxcox1p(dataframe[feat], lam)        \n",
    "            dataframe[feat] = PT_transformer.fit_transform(dataframe[feat].values.reshape(-1,1))\n",
    "        \n",
    "            \n",
    "        cat_vars = [\n",
    "            #'mora_max',\n",
    "            #'estado_civil',\n",
    "            #'rep_calif_cred',\n",
    "            #'ocupacion',\n",
    "            'tipo_vivienda',\n",
    "            #'nivel_academico',\n",
    "            #'departamento_residencia',\n",
    "            #\"ind_mora_vigente\",\n",
    "            #\"cat_edad\",\n",
    "            #\"periodo\"\n",
    "        ]\n",
    "        if cat_vars:\n",
    "            dummified = []\n",
    "            for var in cat_vars:            \n",
    "                dummified.append(\n",
    "                    pd.get_dummies(dataframe[var], drop_first=True, prefix=var)\n",
    "                )\n",
    "\n",
    "            dummified = pd.concat(dummified, axis=1)\n",
    "            dataframe = pd.concat([dataframe.drop(cat_vars, axis=1),dummified], axis=1)\n",
    "            \n",
    "        cluster_variables = [\n",
    "            'cuota_cred_hipot',\n",
    "            'cuota_tarjeta_de_credito',\n",
    "            'cuota_de_consumo',\n",
    "            'cuota_rotativos',\n",
    "            'cuota_sector_real_comercio',\n",
    "            'cuota_de_sector_solidario',\n",
    "            'cuota_tc_bancolombia',\n",
    "            'cuota_libranza_sf',\n",
    "            \"ingreso_corr\",\n",
    "            \"cupo_tc_mdo\",\n",
    "            \"nro_tot_cuentas\",\n",
    "            \"mediana_nom3\",\n",
    "            \"mediana_pen3\",\n",
    "            \"cant_oblig_tot_sf\",\n",
    "            \"saldo_prom3_tdc_mdo\",\n",
    "            \"cupo_total_tc\",\n",
    "            \"saldo_no_rot_mdo\"\n",
    "        ]\n",
    "            \n",
    "        #gmm =GaussianMixture(n_components=5, random_state=1).fit_predict(dataframe[cluster_variables])\n",
    "        #dataframe['cluster'] = gmm\n",
    "        ## Final cleaning\n",
    "        \n",
    "        dataframe.drop([\"ingreso_final\", \"ingreso_calculado\",\n",
    "                        \"cuota_de_vivienda\", \n",
    "                        \"gasto_familiar\",\n",
    "                        \"cupo_total_tc_pct\", \"cupo_tc_mdo_pct\", \"cupo_disponible\",\n",
    "                        #\"cupo_tc_mdo\",\n",
    "                        #\"cupo_total_tc\",\n",
    "                        \"ingreso_nompen\", \"ingreso_nomina\", \"ingreso_segurida_social\",\n",
    "                        \"ingreso_cero\",\n",
    "                        \"tenencia_tc\", # Alta correlacion con cuota tarjeta de credito\n",
    "                        \"ctas_activas\", # Alta correlacion con nto_tot_cuentas\n",
    "                        \"cuota_cred_hipot_pct\", #altta correlacion con cuota credito hipotecario\n",
    "                        \"cuota_de_consumo_pct\", #Alta correlacion con cuta de consumo\n",
    "                        \"cuota_rotaticos_pct\", # Alta correlacion con cuota de rotativos\n",
    "                        \"cuota_tarjeta_de_credito_pct\",\n",
    "                        \"cuota_de_sector_solidario_pct\",\n",
    "                        \"cuota_sector_real_comercio_pct\",\n",
    "                        \"cuota_libranza_sf_pct\",\n",
    "                        \"cuota_tc_bancolombia_pct\",\n",
    "                        \"cuota_rotativos_pct\",\n",
    "                        # REVISAR BIEN\n",
    "                        #\"saldo_no_rot_mdo\",\n",
    "                        \"total_cuota\",\n",
    "                        \"convenio_lib\",\n",
    "                        \"ind_mora_vigente\",\n",
    "                        #'cuota_cred_hipot',\n",
    "                        #'cuota_tarjeta_de_credito',\n",
    "                        #'cuota_de_consumo',\n",
    "                        #'cuota_rotativos',\n",
    "                        #'cuota_sector_real_comercio',\n",
    "                        #'cuota_de_sector_solidario',\n",
    "                        #'cuota_tc_bancolombia',\n",
    "                        #'cuota_libranza_sf',\n",
    "                        \"tiene_consumo\",\n",
    "                        #\"cuota_tc_mdo\",\n",
    "                        \"tiene_crediagil\",\n",
    "                        #\"nivel_academico\",\n",
    "                        \"total_cupo\",\n",
    "                        #\"genero\",\n",
    "                        #\"nro_tot_cuentas\",\n",
    "                        #\"mediana_nom3\",\n",
    "                        #\"mediana_pen3\",\n",
    "                        #\"cant_oblig_tot_sf\",\n",
    "                        #\"saldo_prom3_tdc_mdo\",\n",
    "                        #\"categoria\",\n",
    "                        \"cuota_pct_cupo\",\n",
    "                        \"edad\",\n",
    "                        #\"ind_caida_gasto\",\n",
    "                        #\"ind_caida_cuota\",\n",
    "                        #\"Fecha\",\n",
    "                        #\"periodo\"\n",
    "                        \"mora_max\",\n",
    "                       ], axis=1, inplace=True,  errors='ignore')\n",
    "\n",
    "        return dataframe\n",
    "    \n",
    "    def process(self):\n",
    "        \n",
    "        complete_df = self.columnFilter(\n",
    "                self.handleMissingData(self.original_dataframe)\n",
    "        )\n",
    "        if not self.test:\n",
    "            filtered_df = self.rowFilter(complete_df)\n",
    "            grown_df    = self.processVars(filtered_df)\n",
    "        else:\n",
    "            grown_df    = self.processVars(complete_df)\n",
    "        self.modeling_dataframe = grown_df\n",
    "        \n",
    "        return self.modeling_dataframe\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-knife",
   "metadata": {},
   "source": [
    "# Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hora de inicio: {datetime.now()}\")\n",
    "dates = [\n",
    "    '201902', '201903', '201904', '201905', '201907', '201908', '201909',\n",
    "    '201910', '201911', '202001', '202002', '202003', '202004', '202005',\n",
    "    '202007', '202008', '202009', '202010', '202011'\n",
    "]\n",
    "\n",
    "test_df = pd.read_csv(\"test_cleaned.csv\")\n",
    "test_df['cuota_de_consumo'] = np.where(test_df['cuota_de_consumo'] <0 ,0, test_df['cuota_de_consumo'])\n",
    "test_df_modeling = DataFramePreProcessor(test_df, test=True)\n",
    "test_df_modeling.process()\n",
    "\n",
    "last_predictions_list = []\n",
    "y_tests = []\n",
    "x_tests = []\n",
    "y_preds = []\n",
    "mapes   = []\n",
    "models = []\n",
    "p = 0.001\n",
    "\n",
    "callback = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
    "optimizer   = Adam(learning_rate=0.003)\n",
    "nn_metric = MeanAbsolutePercentageError(name='mape') \n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "with open('tuned_hyper_parameters.json') as f:\n",
    "    tuned_hyperparameters = json.load(f)\n",
    "\n",
    "for date in dates:\n",
    "    print(f\"Periodo {date}:\")\n",
    "    raw_dataframe = pd.read_csv(\n",
    "             f\"train_{date}_cleaned.csv\",\n",
    "             header=0,\n",
    "             skiprows=lambda i: i>0 and random.random() > p\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "    \n",
    "    print(f\"     Total rows in original_data {raw_dataframe.shape[0]}\" )\n",
    "    fe_dataframe = DataFramePreProcessor(raw_dataframe)\n",
    "    fe_dataframe.process()\n",
    "    X = fe_dataframe.modeling_dataframe.drop([ \"log_gasto_familiar\",\n",
    "                                         \"periodo\"], axis=1)\n",
    "    y = fe_dataframe.modeling_dataframe['log_gasto_familiar']\n",
    "    print(f\"     Total rows in transformed_data {fe_dataframe.modeling_dataframe.shape[0]}\" )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)\n",
    "\n",
    "    \n",
    "    # RED NEURONAL\n",
    "    nn_model = Sequential()\n",
    "    \n",
    "    nn_model.add(Dense(128, activation = 'relu', input_shape = (X.shape[1],))) \n",
    "    nn_model.add(Dropout(0.5))\n",
    "    nn_model.add(BatchNormalization())\n",
    "    nn_model.add(Dense(64, activation = 'tanh'))\n",
    "    nn_model.add(Dropout(0.5))\n",
    "    nn_model.add(Dense(1))\n",
    "    nn_model.compile(optimizer =  optimizer, loss = 'mse', metrics = nn_metric)\n",
    "    history  = nn_model.fit(X_train, y_train, epochs=20, callbacks=[callback], validation_split = 0.2)\n",
    "    \n",
    "    \n",
    "    models.append(nn_model)\n",
    "\n",
    "    nn_pred = nn_model.predict(X_test).reshape(-1,)\n",
    "    y_tests.append(y_test)\n",
    "    x_tests.append(X_test)\n",
    "\n",
    "    mape = mean_absolute_percentage_error(nn_pred, y_test)\n",
    "    mapes.append(mape)\n",
    "    print(f\"     MAPE {date}: \", mape )\n",
    "\n",
    "print(f\"Hora de finalizacion: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-bhutan",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-portsmouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = test_df_modeling.modeling_dataframe.drop([\"id_registro\", \"periodo\"], axis=1)\n",
    "\n",
    "nn_stack_predictions = []\n",
    "for model in models:\n",
    "    nn_stack_predictions.append(model.predict(predictions_df).reshape(-1,))\n",
    "nn_stack = np.expm1(np.mean(nn_stack_predictions, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([test_df['id_registro'],pd.Series(nn_stack)], axis=1)\n",
    "submission.columns = [\"id_registro\", \"gasto_familiar\"]\n",
    "submission['gasto_familiar'] = submission['gasto_familiar'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_underground_nn.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
